{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zlw1225/MPLC_CUDA/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf2QOKH6zwJj",
        "outputId": "fa2c0ac6-44d7-4bbd-9852-9bb3389f292b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "git version 2.34.1\n"
          ]
        }
      ],
      "source": [
        "!git --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSqwNWfxz44v",
        "outputId": "4339ad50-2269-40b1-d4dd-872eaa4d59e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MPLC_CUDA'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 9 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (9/9), 17.57 MiB | 12.41 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zlw1225/MPLC_CUDA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xndSOjgqzJcq",
        "outputId": "e4d9588c-7575-42bf-e262-6a9499c7c7d8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/MPLC_CUDA'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "path=\"/content/MPLC_CUDA\"\n",
        "os.chdir(path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8irrMHU1NF_",
        "outputId": "3504323c-f4b9-447b-a96e-e5250873d3ca"
      },
      "outputs": [],
      "source": [
        "!python MPLC_CUDA2.py --iterations 2 --calc_perf_every_it 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "D:/ZLW/project/MPLC_CUDA/.venv/Scripts/python.exe MPLC_CUDA2.py --iterations 2 --calc_perf_every_it 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "function ClickConnect() {\n",
        "  var connectButton = document.querySelector(\"colab-toolbar-button#connect\");\n",
        "  if(connectButton != null) {\n",
        "    console.log(\"Working\"); \n",
        "    connectButton.click();\n",
        "  }\n",
        "}\n",
        "setInterval(ClickConnect, 60000);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "# custom functions imported from the utils.py file available within the package\n",
        "from utils import *\n",
        "\n",
        "DEFAULTS = {\n",
        "    \"n_of_modes\": 10,\n",
        "    \"Planes\": 9,\n",
        "    \"iterations\": 300,\n",
        "    # objective weights\n",
        "    \"alpha\": 1.0,\n",
        "    \"beta\": 2.0,\n",
        "    \"gamma\": 0.0,\n",
        "    # optimization schedule\n",
        "    \"first_n_iterations\": 10,\n",
        "    \"delta_theta_1\": 2*math.pi/255,  # usual step size\n",
        "    \"delta_theta_0\": 10*(2*math.pi/255),  # bigger step size (default 10x)\n",
        "    # sampling / optics\n",
        "    \"Nx\": 512,\n",
        "    \"Ny\": 512,\n",
        "    \"pixelSize\": 8e-6,\n",
        "    \"wavelength\": 1.57e-6,\n",
        "    # propagation distances\n",
        "    \"d_in\": 20e-3,\n",
        "    \"d\": 2*9.7e-3,\n",
        "    \"d_out\": 15e-3,\n",
        "    # evaluation cadence / early stop scale\n",
        "    \"calc_perf_every_it\": 10,\n",
        "    # features\n",
        "    \"equalize_efficiency\": 1,\n",
        "    \"plot_eff_distribution\": 0,\n",
        "    \"smoothing_switch\": 1,\n",
        "    # smoothing strength\n",
        "    \"OffsetMultiplier\": 0e-5,\n",
        "    # extras\n",
        "    \"plot_results\": 0,\n",
        "    \"do_padded_eval\": 0,\n",
        "}\n",
        "\n",
        "def parse_cfg() -> dict:\n",
        "    parser = argparse.ArgumentParser(add_help=True)\n",
        "    # ints\n",
        "    parser.add_argument(\"--n_of_modes\", type=int, default=None)\n",
        "    parser.add_argument(\"--Planes\", type=int, default=None)\n",
        "    parser.add_argument(\"--iterations\", type=int, default=None)\n",
        "    parser.add_argument(\"--first_n_iterations\", type=int, default=None)\n",
        "    parser.add_argument(\"--Nx\", type=int, default=None)\n",
        "    parser.add_argument(\"--Ny\", type=int, default=None)\n",
        "    parser.add_argument(\"--calc_perf_every_it\", type=int, default=None)\n",
        "    parser.add_argument(\"--equalize_efficiency\", type=int, choices=[0,1], default=None)\n",
        "    parser.add_argument(\"--plot_eff_distribution\", type=int, choices=[0,1], default=None)\n",
        "    parser.add_argument(\"--smoothing_switch\", type=int, choices=[0,1], default=None)\n",
        "    parser.add_argument(\"--plot_results\", type=int, choices=[0,1], default=None)\n",
        "    parser.add_argument(\"--do_padded_eval\", type=int, choices=[0,1], default=None)\n",
        "    # floats\n",
        "    parser.add_argument(\"--alpha\", type=float, default=None)\n",
        "    parser.add_argument(\"--beta\", type=float, default=None)\n",
        "    parser.add_argument(\"--gamma\", type=float, default=None)\n",
        "    parser.add_argument(\"--delta_theta_1\", type=float, default=None)\n",
        "    parser.add_argument(\"--delta_theta_0\", type=float, default=None)\n",
        "    parser.add_argument(\"--pixelSize\", type=float, default=None)\n",
        "    parser.add_argument(\"--wavelength\", type=float, default=None)\n",
        "    parser.add_argument(\"--d_in\", type=float, default=None)\n",
        "    parser.add_argument(\"--d\", type=float, default=None)\n",
        "    parser.add_argument(\"--d_out\", type=float, default=None)\n",
        "    parser.add_argument(\"--OffsetMultiplier\", type=float, default=None)\n",
        "\n",
        "    try:\n",
        "        args = parser.parse_args()\n",
        "    except SystemExit:\n",
        "        # in notebooks or if imported, ignore CLI parsing side-effect\n",
        "        args = argparse.Namespace()\n",
        "    cfg = DEFAULTS.copy()\n",
        "    for k, v in vars(args).items() if hasattr(args, \"__dict__\") else []:\n",
        "        if v is not None:\n",
        "            cfg[k] = v\n",
        "    return cfg\n",
        "\n",
        "CFG = parse_cfg()\n",
        "\n",
        "# concise explicit unpacking (friendly to linters and readers)\n",
        "(n_of_modes, Planes, iterations,\n",
        " alpha, beta, gamma,\n",
        " first_n_iterations, delta_theta_1, delta_theta_0,\n",
        " Nx, Ny, pixelSize, wavelength,\n",
        " d_in, d, d_out,\n",
        " calc_perf_every_it,\n",
        " equalize_efficiency, plot_eff_distribution, smoothing_switch, OffsetMultiplier) = (\n",
        "     CFG[\"n_of_modes\"], CFG[\"Planes\"], CFG[\"iterations\"],\n",
        "     CFG[\"alpha\"], CFG[\"beta\"], CFG[\"gamma\"],\n",
        "     CFG[\"first_n_iterations\"], CFG[\"delta_theta_1\"], CFG[\"delta_theta_0\"],\n",
        "     CFG[\"Nx\"], CFG[\"Ny\"], CFG[\"pixelSize\"], CFG[\"wavelength\"],\n",
        "     CFG[\"d_in\"], CFG[\"d\"], CFG[\"d_out\"],\n",
        "     CFG[\"calc_perf_every_it\"],\n",
        "     CFG[\"equalize_efficiency\"], CFG[\"plot_eff_distribution\"], CFG[\"smoothing_switch\"], CFG[\"OffsetMultiplier\"])\n",
        "\n",
        "# Select device (prefer CUDA)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"[MPLC2] Using device: {DEVICE}\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    try:\n",
        "        name = torch.cuda.get_device_name(0)\n",
        "        cap = torch.cuda.get_device_capability(0)\n",
        "        print(f\"[MPLC2] GPU: {name}, capability={cap}, torch_cuda={getattr(torch.version, 'cuda', None)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[MPLC2] CUDA detected but failed to query device info: {e}\")\n",
        "else:\n",
        "    print(\"[MPLC2] CUDA 不可用：将使用 CPU 运行。若期望使用 GPU，请安装 CUDA 版 PyTorch 并确保驱动正确。\")\n",
        "\n",
        "# derived parameters\n",
        "reprW, reprH = Nx * pixelSize, Ny * pixelSize\n",
        "crs_delta = 0.0001 * calc_perf_every_it\n",
        "maskOffset = OffsetMultiplier * np.sqrt(1e-3 / (Nx * Ny * n_of_modes))\n",
        "\n",
        "# wavelength-independent grids\n",
        "nx_m = pixelSize*np.linspace(-(Nx-1)/2, (Nx-1)/2, num=Nx)\n",
        "ny_m = pixelSize*np.linspace(-(Ny-1)/2, (Ny-1)/2, num=Ny)\n",
        "X,Y = np.meshgrid(nx_m,ny_m)\n",
        "X_torch = torch.from_numpy(X).to(DEVICE)\n",
        "Y_torch = torch.from_numpy(Y).to(DEVICE)\n",
        "\n",
        "nx = np.linspace(-(Nx-1)/2, (Nx-1)/2, num=Nx)\n",
        "ny = np.linspace(-(Ny-1)/2, (Ny-1)/2, num=Ny)\n",
        "kx, ky = np.meshgrid(2*np.pi*nx/(Nx*pixelSize),2*np.pi*ny/(Ny*pixelSize))\n",
        "\n",
        "\n",
        "lambda_list = np.array([1.53e-6, 1.55e-6, 1.57e-6, 1.59e-6, 1.61e-6, 1.625e-6], dtype=np.float64)\n",
        "lambda_c = 1.57e-6\n",
        "\n",
        "# 读取LP模式和高斯输出（多波长）\n",
        "lp_data = np.load('modes_lp_10.npz')\n",
        "lp_modes = lp_data['profiles']  # 形状: (L, 10, 512, 512)\n",
        "gauss_data = np.load('gauss_5x2_custom.npz')\n",
        "gauss_modes = gauss_data['profiles']  # 形状: (L, 10, 512, 512)\n",
        "\n",
        "L = min(lp_modes.shape[0], gauss_modes.shape[0], len(lambda_list))\n",
        "lambda_list = lambda_list[:L]\n",
        "\n",
        "Speckle_basis = lp_modes[:L, 0:n_of_modes, :, :]\n",
        "Gaussian_basis = gauss_modes[:L, 0:n_of_modes, :, :]\n",
        "Speckle_basis_torch = torch.from_numpy(Speckle_basis).to(torch.cdouble).to(DEVICE)\n",
        "Gaussian_basis_torch = torch.from_numpy(Gaussian_basis).to(torch.cdouble).to(DEVICE)\n",
        "\n",
        "# 生成多波长高斯mask\n",
        "Gaussian_Masks = np.zeros_like(Gaussian_basis, dtype=np.float64)\n",
        "for l in range(L):\n",
        "    for m in range(n_of_modes):\n",
        "        inten = np.abs(Gaussian_basis[l, m, :, :]) ** 2\n",
        "        thr = 0.05 * np.max(inten)\n",
        "        Gaussian_Masks[l, m, :, :] = inten > thr\n",
        "Gaussian_Masks_torch = torch.from_numpy(Gaussian_Masks).to(torch.double).to(DEVICE)\n",
        "\n",
        "# 若需要pad\n",
        "if (Nx > 512) or (Ny > 512):\n",
        "    pad_x = int((Nx-512)/2)\n",
        "    pad_y = int((Ny-512)/2)\n",
        "    Speckle_basis_torch = nn.functional.pad(Speckle_basis_torch, (pad_x, Nx-512-pad_x, pad_y, Ny-512-pad_y), mode='constant', value=0.+0.j)\n",
        "    Gaussian_basis_torch = nn.functional.pad(Gaussian_basis_torch, (pad_x, Nx-512-pad_x, pad_y, Ny-512-pad_y), mode='constant', value=0.+0.j)\n",
        "    Gaussian_Masks_torch = nn.functional.pad(Gaussian_Masks_torch, (pad_x, Nx-512-pad_x, pad_y, Ny-512-pad_y), mode='constant', value=0.0)\n",
        "\n",
        "# 多波长下的 phi_bk 与 phi_cr\n",
        "phi_bk = torch.ones((Gaussian_Masks_torch.shape[0], Ny, Nx), dtype=torch.double, device=DEVICE) - torch.sum(Gaussian_Masks_torch, axis = 1)\n",
        "phi_cr = torch.zeros((Gaussian_Masks_torch.shape[0], n_of_modes, Ny, Nx), dtype = torch.double, device=DEVICE)\n",
        "for l in range(Gaussian_Masks_torch.shape[0]):\n",
        "    for i in range(n_of_modes):\n",
        "        phi_cr[l,i,:,:] = torch.sum(Gaussian_Masks_torch[l], axis = 0) - Gaussian_Masks_torch[l,i,:,:]\n",
        "\n",
        "phi = Gaussian_basis_torch\n",
        "\n",
        "# # visualize one of the input modes, a set of Gaussians on the outputs and a binary mask outlining the backgroud region\n",
        "# # brightness = amplitude, colour = phase\n",
        "# plt.title(\"One of the input modes - $\\chi_{0}$\")\n",
        "# complim(Speckle_basis_torch[0, :, :])\n",
        "\n",
        "# plt.title(\"Sum of the output modes - $\\sum\\phi_{i}$\")\n",
        "# complim(torch.sum(phi, axis = 0))\n",
        "\n",
        "# plt.title(\"$\\phi^{bk}$\")\n",
        "# complim(phi_bk)\n",
        "\n",
        "# plt.title(\"$\\phi_{0}^{cr}$\")\n",
        "# complim(phi_cr[0,:,:])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Masks = torch.zeros((Planes,Ny,Nx), dtype=torch.double, device=DEVICE) # use zero phases as starting guesses for the phase masks\n",
        "Masks_complex = torch.exp(1j*Masks) # complex representation of the phase masks with amplitude = 1 everywhere\n",
        "\n",
        "# create placeholder arrays to store every input and every output field in each plane\n",
        "L = Gaussian_Masks_torch.shape[0]\n",
        "Modes_in = torch.zeros((L, Planes, n_of_modes, Ny, Nx), dtype = torch.cdouble, device=DEVICE)\n",
        "Modes_out = torch.zeros((L, Planes, n_of_modes, Ny, Nx), dtype = torch.cdouble, device=DEVICE)\n",
        "\n",
        "overlap = torch.zeros((n_of_modes), dtype = torch.cdouble, device=DEVICE)\n",
        "eff_distribution = torch.ones((n_of_modes), dtype = torch.double, device=DEVICE)\n",
        "dFdpsi = torch.zeros((L, Planes, n_of_modes, Ny, Nx), dtype = torch.cdouble, device=DEVICE)\n",
        "crs_array_convergence = torch.zeros((iterations//calc_perf_every_it), dtype = torch.double, device=DEVICE)\n",
        "conv_count = 0\n",
        "\n",
        "# 每个波长的 kz，初始化 Modes_in/Out\n",
        "kz_torch_list = []\n",
        "for l in range(L):\n",
        "    k_l = (2*np.pi)/lambda_list[l]\n",
        "    kz_l = np.sqrt(k_l**2 - (kx**2 + ky**2))\n",
        "    kz_torch_list.append(torch.from_numpy(kz_l.astype(np.cdouble)).to(DEVICE))\n",
        "    Modes_in[l, 0, :, :, :] = propagate_HK(Speckle_basis_torch[l], kz_torch_list[l], d_in)\n",
        "    # 目标场定义在输出面（距最后一面 d_out 处），用于反向传播到最后一面\n",
        "    Modes_out[l, Planes-1, :, :, :] = propagate_HK(phi[l], kz_torch_list[l], -d_out)\n",
        "\n",
        "# iterate \n",
        "for i in range(1, iterations+1):\n",
        "\n",
        "    # change the step size depending on the current iteration number\n",
        "    if i < first_n_iterations:\n",
        "        delta_theta = delta_theta_0\n",
        "    else:\n",
        "        delta_theta = delta_theta_1\n",
        "\n",
        "    # update all the phase masks on this iteration in an ascending order\n",
        "    for mask_ind in range(Planes):\n",
        "\n",
        "        # 多波长：按 λ 比例缩放相位并分别前后传播\n",
        "        for l in range(L):\n",
        "            scale_l = lambda_c / lambda_list[l]\n",
        "            modes = torch.zeros((n_of_modes, Ny, Nx), dtype = torch.cdouble, device=DEVICE)\n",
        "            for pl in range(Planes-1):\n",
        "                mask_cmplx_l = torch.exp(1j*(Masks[pl, :, :]*scale_l))\n",
        "                modes = Modes_in[l, pl, :, :, :] * mask_cmplx_l\n",
        "                modes = propagate_HK(modes, kz_torch_list[l], d)\n",
        "                Modes_in[l, pl+1, :, :, :] = modes\n",
        "            modes_forw_last_plane = Modes_in[l, Planes-1, :, :, :] * torch.exp(1j*(Masks[Planes-1, :, :]*scale_l))\n",
        "            # 从最后一面向前传播到真实输出面 z_out\n",
        "            eout_l = propagate_HK(modes_forw_last_plane, kz_torch_list[l], d_out)\n",
        "\n",
        "            for j in range(n_of_modes):\n",
        "                overlap = torch.sum(torch.squeeze(eout_l[j,:,:]) * torch.conj(torch.squeeze(phi[l,j,:,:])))\n",
        "                a = (phi[l, j, :, :]) * overlap\n",
        "                psi_cr_l = (torch.squeeze(eout_l[j,:,:])) * torch.squeeze(phi_cr[l,j,:,:])\n",
        "                psi_bk_l = (torch.squeeze(eout_l[j,:,:])) * phi_bk[l]\n",
        "                dFdpsi[l, Planes-1, j, :, :] = - alpha*a + (beta*psi_cr_l - gamma*psi_bk_l)*0.5\n",
        "\n",
        "            # 将输出面上的梯度场反向传播回最后一面\n",
        "            dFdpsi[l, Planes-1, :, :, :] = propagate_HK(dFdpsi[l, Planes-1, :, :, :], kz_torch_list[l], -d_out)\n",
        "\n",
        "            for pl in range(Planes-1, mask_ind, -1):\n",
        "                mask_cmplx_l = torch.exp(1j*(Masks[pl, :, :]*scale_l))\n",
        "                dFdpsi_prop = dFdpsi[l, pl, :, :, :] * torch.conj(mask_cmplx_l)\n",
        "                dFdpsi_prop = propagate_HK(dFdpsi_prop, kz_torch_list[l], -d)\n",
        "                dFdpsi[l, pl-1, :, :, :] = dFdpsi_prop\n",
        "\n",
        "                phi_prop = Modes_out[l, pl, :, :, :] * torch.conj(mask_cmplx_l)\n",
        "                phi_prop = propagate_HK(phi_prop, kz_torch_list[l], -d)\n",
        "                Modes_out[l, pl-1, :, :, :] = phi_prop\n",
        "\n",
        "        # if equalize_efficiency is on, make a sum in (1) a weighted sum, where the weights are 1/(relative_efficiency_i) for each particular mode            \n",
        "        if equalize_efficiency == 1:\n",
        "            total_term = torch.zeros((Ny,Nx), dtype=torch.cdouble, device=DEVICE)\n",
        "            for l in range(L):\n",
        "                scale_l = lambda_c / lambda_list[l]\n",
        "                mask_cmplx_l = torch.exp(1j*(Masks[mask_ind, :, :]*scale_l))\n",
        "                weighted_overlaps = torch.zeros((Ny,Nx), dtype=torch.cdouble, device=DEVICE)\n",
        "                for mode in range(n_of_modes):\n",
        "                    weighted_overlaps = weighted_overlaps + (1/eff_distribution[mode]) * torch.squeeze(Modes_in[l, mask_ind, mode, :, :]) * torch.conj(torch.squeeze(dFdpsi[l, mask_ind, mode, :, :]))\n",
        "                total_term = total_term + mask_cmplx_l * weighted_overlaps\n",
        "            delta_P = delta_theta*torch.sign(torch.imag(total_term))\n",
        "        else:\n",
        "            total_term = torch.zeros((Ny,Nx), dtype=torch.cdouble, device=DEVICE)\n",
        "            for l in range(L):\n",
        "                scale_l = lambda_c / lambda_list[l]\n",
        "                mask_cmplx_l = torch.exp(1j*(Masks[mask_ind, :, :]*scale_l))\n",
        "                overlaps = torch.sum(torch.squeeze(Modes_in[l, mask_ind, :, :, :]) * torch.conj(torch.squeeze(dFdpsi[l, mask_ind, :, :, :])), axis = 0)\n",
        "                total_term = total_term + mask_cmplx_l * overlaps\n",
        "            delta_P = delta_theta*torch.sign(torch.imag(total_term))\n",
        "        \n",
        "        #  if smoothing_switch is on, mask the regions of the phase masks where there is almost no incedent light, based on the overlap of input and output modes at this plane\n",
        "        if smoothing_switch == 1:\n",
        "                ov_sum = torch.zeros((Ny, Nx), dtype=torch.double, device=DEVICE)\n",
        "                for l in range(L):\n",
        "                    ov_sum = ov_sum + torch.abs(torch.sum(torch.squeeze(Modes_in[l, mask_ind, :, :, :]*torch.conj(Modes_out[l, mask_ind, :, :, :])), axis = 0))\n",
        "                ovrlp_in_out = ov_sum / L\n",
        "                mask_cmplx = ovrlp_in_out*torch.exp(1j*(Masks[mask_ind, :, :] + delta_P)) \n",
        "                mask_cmplx = mask_cmplx + maskOffset\n",
        "                Masks[mask_ind, :, :] = torch.angle(mask_cmplx)\n",
        "        #  if smoothing_switch is off, just add phase delta_P to a current guess of the certain phase mask\n",
        "        else:\n",
        "            Masks[mask_ind, :, :] = Masks[mask_ind, :, :] + delta_P\n",
        "\n",
        "        # store the resulting current guess of the phase mask as a complex array, with amplitude = 1 everywhere\n",
        "        Masks_complex[mask_ind, :, :] = torch.exp(1j*torch.squeeze(Masks[mask_ind, :, :]))\n",
        "\n",
        "\n",
        "    # calculate and print out sorter's performance after every iteration (or every K iterations to save time)\n",
        "    if i % calc_perf_every_it == 0:\n",
        "        fids = []\n",
        "        crss = []\n",
        "        effs = []\n",
        "        for l in range(L):\n",
        "            scale_l = lambda_c / lambda_list[l]\n",
        "            for pl in range(Planes-1):\n",
        "                mask_cmplx_l = torch.exp(1j*(Masks[pl, :, :]*scale_l))\n",
        "                modes = Modes_in[l, pl, :, :, :]*mask_cmplx_l\n",
        "                modes = propagate_HK(modes, kz_torch_list[l], d)\n",
        "                Modes_in[l, pl+1, :, :, :] = modes\n",
        "            modes = modes*torch.exp(1j*(Masks[Planes-1, :, :]*scale_l))\n",
        "            eout = propagate_HK(modes, kz_torch_list[l], d_out)\n",
        "            eout_int_only = (torch.abs(eout))**2\n",
        "            fid, _ = performance_loc_fidelity(eout, Gaussian_Masks_torch[l], phi[l]) \n",
        "            crs, _, _ = performance_crosstalk(eout_int_only, Gaussian_Masks_torch[l]) \n",
        "            eff, eff_list = performance_efficiency(eout_int_only, Gaussian_Masks_torch[l])\n",
        "            fids.append(fid); crss.append(crs); effs.append(eff)\n",
        "\n",
        "        fid = torch.stack(fids).mean(); crs = torch.stack(crss).mean(); eff = torch.stack(effs).mean()\n",
        "        print('iteration', i, ': loc. fidelity =', round(fid.detach().cpu().numpy().item(),2), ', crosstalk =', round(crs.detach().cpu().numpy().item(),2), ', efficiency =', round(eff.detach().cpu().numpy().item(),2))\n",
        "        crs_array_convergence[conv_count] = crs # store calculated cross-talk to an array to then plot it against the number of iterations\n",
        "        \n",
        "        # stop iterating if the algorithm is no longer improving cross-talk by more than a certain value after a certain iteration\n",
        "        if i > (iterations/3) and (crs_array_convergence[conv_count-1] - crs_array_convergence[conv_count]) < crs_delta:\n",
        "            break\n",
        "        conv_count = conv_count + 1\n",
        "\n",
        "        # store a list of a relative efficiency of every output on the current iteration to try to equalize them on the next run\n",
        "        if equalize_efficiency == 1:\n",
        "            eff_distribution = eff_list/torch.max(eff_list)\n",
        "            # plot efficiency distribution if plot_eff_distribution is on\n",
        "            if plot_eff_distribution == 1:                    \n",
        "                plt.plot(eff_distribution)\n",
        "                plt.title('efficiency distribution')\n",
        "                plt.ylim((0,1))\n",
        "                plt.show()\n",
        "        \n",
        "fids = []; crss = []; effs = []\n",
        "for l in range(L):\n",
        "    scale_l = lambda_c / lambda_list[l]\n",
        "    for pl in range(Planes-1):\n",
        "        modes = Modes_in[l, pl, :, :, :]*torch.exp(1j*(Masks[pl, :, :]*scale_l))\n",
        "        modes = propagate_HK(modes, kz_torch_list[l], d)\n",
        "        Modes_in[l, pl+1, :, :, :] = modes\n",
        "    modes = modes*torch.exp(1j*(Masks[Planes-1, :, :]*scale_l))\n",
        "    eout = propagate_HK(modes, kz_torch_list[l], d_out)\n",
        "    eout_int_only = (torch.abs(eout))**2\n",
        "    fid, _ = performance_loc_fidelity(eout, Gaussian_Masks_torch[l], phi[l])\n",
        "    crs, _, _ = performance_crosstalk(eout_int_only, Gaussian_Masks_torch[l])\n",
        "    eff, _ = performance_efficiency(eout_int_only, Gaussian_Masks_torch[l])\n",
        "    fids.append(fid); crss.append(crs); effs.append(eff)\n",
        "fid = torch.stack(fids).mean(); crs = torch.stack(crss).mean(); eff = torch.stack(effs).mean()\n",
        "print('Final performance (avg over λ): loc. fidelity =', round(fid.detach().cpu().numpy().item(),3), ', crosstalk =', round(crs.detach().cpu().numpy().item(),3), ', efficiency =', round(eff.detach().cpu().numpy().item(),3))\n",
        "\n",
        "if CFG.get(\"plot_results\", 0) == 1:\n",
        "    # 展示相位面\n",
        "    for i in range(Planes):\n",
        "        plt.title(\"Phase mask %s\" %(i+1))\n",
        "        _ = plot_in_GS(Masks[i,:,:])\n",
        "\n",
        "# 逐波长性能打印\n",
        "for idx, (f_i, c_i, e_i) in enumerate(zip(fids, crss, effs)):\n",
        "    print(f\"λ={lambda_list[idx]*1e6:.3f} µm -> fidelity={float(f_i.detach().cpu().numpy()):.3f}, crosstalk={float(c_i.detach().cpu().numpy()):.3f}, efficiency={float(e_i.detach().cpu().numpy()):.3f}\")\n",
        "\n",
        "if CFG.get(\"do_padded_eval\", 0) == 1:\n",
        "    newNx = Nx + 400\n",
        "    newNy = Ny + 400\n",
        "    l_c = 2 if L >= 3 else 0\n",
        "    Modes_in_wide = torch.zeros((Planes,n_of_modes,newNx,newNy), dtype=torch.cdouble)\n",
        "    Modes_in_wide[0,:,200:200+Nx,200:200+Ny] = Modes_in[l_c,0,:,:,:]\n",
        "    Masks_wide = torch.zeros((Planes,newNy,newNx), dtype = torch.double)\n",
        "    Masks_complex_wide = torch.exp(1j*Masks_wide)\n",
        "    Masks_complex_wide[:,200:200+Nx,200:200+Ny] = Masks_complex\n",
        "    nx_wide = np.linspace(-(newNx-1)/2, (newNx-1)/2, num=newNx)\n",
        "    ny_wide = np.linspace(-(newNy-1)/2, (newNy-1)/2, num=newNy)\n",
        "    kx_wide, ky_wide = np.meshgrid(2*np.pi*nx_wide/(newNx*pixelSize),2*np.pi*ny_wide/(newNy*pixelSize))\n",
        "    kz_wide = np.sqrt((2*np.pi/lambda_c)**2 - (kx_wide**2 + ky_wide**2)).astype(np.cdouble)\n",
        "    kz_torch_wide = torch.from_numpy(kz_wide)\n",
        "    for pl in range(Planes-1):\n",
        "        modes = Modes_in_wide[pl, :, :, :]*Masks_complex_wide[pl, :, :]\n",
        "        modes = propagate_HK(modes, kz_torch_wide, d)\n",
        "        Modes_in_wide[pl+1, :, :, :] = modes\n",
        "    modes = modes*Masks_complex_wide[Planes-1,:,:]\n",
        "    modes_cropped = modes[:,200:200+Nx,200:200+Ny]\n",
        "    # 在宽域上从最后一面传播到输出面，再裁剪评估\n",
        "    eout_wide = propagate_HK(modes, kz_torch_wide, d_out)\n",
        "    eout_cropped = eout_wide[:,200:200+Nx,200:200+Ny]\n",
        "    eout_cropped_int_only = (torch.abs(eout_cropped))**2\n",
        "    fid_wide, _ = performance_loc_fidelity(eout_cropped, Gaussian_Masks_torch[l_c], phi[l_c])\n",
        "    crs_wide, _, _ = performance_crosstalk(eout_cropped_int_only, Gaussian_Masks_torch[l_c])\n",
        "    eff_wide, _ = performance_efficiency(eout_cropped_int_only, Gaussian_Masks_torch[l_c])\n",
        "    print('performance padded (λc): loc. fidelity =', round(fid_wide.detach().numpy().item(),3), ', crosstalk =', round(crs_wide.detach().numpy().item(),3), ', efficiency =', round(eff_wide.detach().numpy().item(),3))\n",
        "\n",
        "    plt.plot(crs_array_convergence)\n",
        "    plt.ylabel('avg. crosstalk (avg over λ)')\n",
        "    plt.xlabel('iterations/(calc_perf_every_it)')\n",
        "    plt.axis([0, iterations//calc_perf_every_it, 0, 20])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Visualization: λ=1.57 μm 前/后向“相位前”分布与相位图\n",
        "# - 前向快照: z=0, p0..p6 的 pre-phase (传播到该面, 未乘该面相位), 以及 z_out\n",
        "# - 后向快照: z_out, p6..p0 的 pre-phase (从后向传播到该面, 未乘该面相位), 以及 z=0\n",
        "# ==========================================\n",
        "import os\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # 选择 λ=1.57 μm 的索引\n",
        "    l_idx = int(np.argmin(np.abs(lambda_list - lambda_c)))\n",
        "    kz_l = kz_torch_list[l_idx]\n",
        "    scale_l = lambda_c / lambda_list[l_idx]\n",
        "\n",
        "    # 前向: 收集相位前快照（总强度=所有模式强度求和）\n",
        "    fwd_titles = []\n",
        "    fwd_maps = []\n",
        "    # z=0\n",
        "    modes = Speckle_basis_torch[l_idx].clone()\n",
        "    fwd_maps.append(torch.sum(torch.abs(modes) ** 2, dim=0))\n",
        "    fwd_titles.append('z=0')\n",
        "    # 传播到 p0 (pre-phase)\n",
        "    modes = propagate_HK(modes, kz_l, d_in)\n",
        "    fwd_maps.append(torch.sum(torch.abs(modes) ** 2, dim=0))\n",
        "    fwd_titles.append('p0 pre')\n",
        "    # 依次到 p1..p6 的 pre-phase\n",
        "    for pl in range(0, Planes-1):  # 到 p1..p6 的pre，需要先在上一面乘相位再传播\n",
        "        mask_cmplx = torch.exp(1j * (Masks[pl] * scale_l))\n",
        "        modes = modes * mask_cmplx\n",
        "        modes = propagate_HK(modes, kz_l, d)\n",
        "        fwd_maps.append(torch.sum(torch.abs(modes) ** 2, dim=0))\n",
        "        fwd_titles.append(f'p{pl+1} pre')\n",
        "    # 输出面 z_out (在 p6 乘相位后传播 d_out)\n",
        "    modes = modes * torch.exp(1j * (Masks[Planes-1] * scale_l))\n",
        "    modes_out = propagate_HK(modes, kz_l, d_out)\n",
        "    fwd_maps.append(torch.sum(torch.abs(modes_out) ** 2, dim=0))\n",
        "    fwd_titles.append('z_out')\n",
        "\n",
        "    # 后向: 从目标输出面场出发，收集各面的 pre-phase\n",
        "    bwd_titles = []\n",
        "    bwd_maps = []\n",
        "    # z_out（目标场）\n",
        "    modes_b = phi[l_idx].clone()\n",
        "    bwd_maps.append(torch.sum(torch.abs(modes_b) ** 2, dim=0))\n",
        "    bwd_titles.append('z_out')\n",
        "    # 到 p6 pre：先 -d_out 到 p6 的后相位(post)，再乘 conj(mask6) 得 pre\n",
        "    modes_b = propagate_HK(modes_b, kz_l, -d_out)\n",
        "    mask6 = torch.exp(1j * (Masks[Planes-1] * scale_l))\n",
        "    modes_b = modes_b * torch.conj(mask6)\n",
        "    bwd_maps.append(torch.sum(torch.abs(modes_b) ** 2, dim=0))\n",
        "    bwd_titles.append('p6 pre')\n",
        "    # 依次到 p5..p0 的 pre：每步先 -d 到达上一面的 post，再乘对应 conj(mask) 得 pre\n",
        "    for pl in range(Planes-2, -1, -1):  # from p5 down to p0\n",
        "        modes_b = propagate_HK(modes_b, kz_l, -d)\n",
        "        mask_cmplx = torch.exp(1j * (Masks[pl] * scale_l))\n",
        "        modes_b = modes_b * torch.conj(mask_cmplx)\n",
        "        bwd_maps.append(torch.sum(torch.abs(modes_b) ** 2, dim=0))\n",
        "        bwd_titles.append(f'p{pl} pre')\n",
        "    # 最后到 z=0：-d_in 传播\n",
        "    modes_b = propagate_HK(modes_b, kz_l, -d_in)\n",
        "    bwd_maps.append(torch.sum(torch.abs(modes_b) ** 2, dim=0))\n",
        "    bwd_titles.append('z=0')\n",
        "\n",
        "    # 画图：前向 9 幅（z=0, p0..p6, z_out）\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig1, axes1 = plt.subplots(3, 3, figsize=(12, 10))\n",
        "    for idx, ax in enumerate(axes1.ravel()):\n",
        "        if idx < len(fwd_maps):\n",
        "            im = ax.imshow(fwd_maps[idx].detach().cpu().numpy(), cmap='inferno', origin='lower')\n",
        "            ax.set_title(fwd_titles[idx])\n",
        "            ax.axis('off')\n",
        "        else:\n",
        "            ax.axis('off')\n",
        "    fig1.suptitle('Forward pre-phase intensity (λ=1.57 μm)')\n",
        "    fig1.tight_layout()\n",
        "    fig1.savefig('results/forward_prephase_1p57.png', dpi=150)\n",
        "\n",
        "    # 画图：后向 9 幅（z_out, p6..p0, z=0）\n",
        "    fig2, axes2 = plt.subplots(3, 3, figsize=(12, 10))\n",
        "    for idx, ax in enumerate(axes2.ravel()):\n",
        "        if idx < len(bwd_maps):\n",
        "            im = ax.imshow(bwd_maps[idx].detach().cpu().numpy(), cmap='inferno', origin='lower')\n",
        "            ax.set_title(bwd_titles[idx])\n",
        "            ax.axis('off')\n",
        "        else:\n",
        "            ax.axis('off')\n",
        "    fig2.suptitle('Backward pre-phase intensity (λ=1.57 μm)')\n",
        "    fig2.tight_layout()\n",
        "    fig2.savefig('results/backward_prephase_1p57.png', dpi=150)\n",
        "\n",
        "    # 相位图：相位面数量自适应（按每行 4 列排布）\n",
        "    ncols = 4\n",
        "    nrows = math.ceil(Planes / ncols)\n",
        "    fig3, axes3 = plt.subplots(nrows, ncols, figsize=(3*ncols, 3*nrows))\n",
        "    # 将 axes 拉平成 1D，便于按索引逐个填充\n",
        "    axes3_flat = np.array(axes3).ravel() if isinstance(axes3, np.ndarray) else np.array([axes3])\n",
        "    for p in range(Planes):\n",
        "        ax = axes3_flat[p]\n",
        "        ax.imshow(Masks[p].detach().cpu().numpy(), cmap='twilight', origin='lower')\n",
        "        ax.set_title(f'Mask p{p}')\n",
        "        ax.axis('off')\n",
        "    # 关掉多余子图\n",
        "    for k in range(Planes, nrows*ncols):\n",
        "        axes3_flat[k].axis('off')\n",
        "    fig3.suptitle('Phase masks (radians)')\n",
        "    fig3.tight_layout()\n",
        "    fig3.savefig('results/masks_phase_maps.png', dpi=150)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Subplot: 六个波长的耦合矩阵 + 指标 (IL, MDL, XTs_avg_dB, fidelity/crosstalk/efficiency)\n",
        "# - 耦合矩阵基于输出面复场与目标复场的归一化内积 C_{m,j}=\n",
        "#   <E_out_m, Phi_j>/sqrt(<E_out_m,E_out_m><Phi_j,Phi_j>)\n",
        "# - IL=10*log10(mean(s^2)), MDL=10*log10(max(s^2)/min(s^2)), XTs_avg_dB=10*log10(mean(((sum|C|^2 - diag|C|^2)/diag|C|^2)))\n",
        "# ==========================================\n",
        "with torch.no_grad():\n",
        "    Nl = len(lambda_list)\n",
        "    modeCount = n_of_modes\n",
        "    ILs = np.zeros(Nl)\n",
        "    MDLs = np.zeros(Nl)\n",
        "    XTs_avg_dB = np.zeros(Nl)\n",
        "    fids_l = np.zeros(Nl)\n",
        "    crss_l = np.zeros(Nl)\n",
        "    effs_l = np.zeros(Nl)\n",
        "\n",
        "    # 预创建子图\n",
        "    nrows, ncols = 2, 3\n",
        "    fig_cm, axes_cm = plt.subplots(nrows, ncols, figsize=(12, 8))\n",
        "\n",
        "    for l in range(Nl):\n",
        "        kz_l = kz_torch_list[l]\n",
        "        scale_l = lambda_c / lambda_list[l]\n",
        "\n",
        "        # 前向到输出面\n",
        "        modes = propagate_HK(Speckle_basis_torch[l], kz_l, d_in)\n",
        "        for pl in range(Planes-1):\n",
        "            modes = modes * torch.exp(1j * (Masks[pl] * scale_l))\n",
        "            modes = propagate_HK(modes, kz_l, d)\n",
        "        modes = modes * torch.exp(1j * (Masks[Planes-1] * scale_l))\n",
        "        eout = propagate_HK(modes, kz_l, d_out)  # (M, Ny, Nx)\n",
        "\n",
        "        # 基于复内积构建耦合矩阵 C (M×M)\n",
        "        E = eout.reshape(modeCount, -1)\n",
        "        P = phi[l].reshape(modeCount, -1)\n",
        "        num = E @ torch.conj(P).T  # (M,M)\n",
        "        normE = torch.sum(torch.abs(E)**2, dim=1)  # (M,)\n",
        "        normP = torch.sum(torch.abs(P)**2, dim=1)  # (M,)\n",
        "        denom = torch.sqrt(normE[:, None] * normP[None, :]) + 1e-12\n",
        "        C = num / denom\n",
        "\n",
        "        # IL / MDL from SVD of C\n",
        "        C_np = C.detach().cpu().numpy()\n",
        "        s = np.linalg.svd(C_np, compute_uv=False)  # singular values\n",
        "        s2 = s**2\n",
        "        ILs[l] = 10 * np.log10(np.mean(s2))\n",
        "        MDLs[l] = 10 * np.log10(np.max(s2) / (np.min(s2) + 1e-15))\n",
        "\n",
        "        # XTs (per mode) and XTs_avg_dB\n",
        "        C2 = np.abs(C_np)**2\n",
        "        totalPower = np.sum(C2, axis=1)\n",
        "        signalPower = np.clip(np.diag(C2), 1e-15, None)\n",
        "        XTs_modes = (totalPower - signalPower) / signalPower\n",
        "        XTs_avg_dB[l] = 10 * np.log10(np.mean(XTs_modes))\n",
        "\n",
        "        # 同时计算 fidelity/crosstalk/efficiency（基于 mask 的原函数）\n",
        "        eout_int = (torch.abs(eout))**2\n",
        "        fid_l, _ = performance_loc_fidelity(eout, Gaussian_Masks_torch[l], phi[l])\n",
        "        crs_l, _, _ = performance_crosstalk(eout_int, Gaussian_Masks_torch[l])\n",
        "        eff_l, _ = performance_efficiency(eout_int, Gaussian_Masks_torch[l])\n",
        "        fids_l[l] = float(fid_l.detach().cpu().numpy())\n",
        "        crss_l[l] = float(crs_l.detach().cpu().numpy())\n",
        "        effs_l[l] = float(eff_l.detach().cpu().numpy())\n",
        "\n",
        "        # 绘制该波长的耦合矩阵（功率 |C|^2）\n",
        "        r = l // ncols\n",
        "        c = l % ncols\n",
        "        ax = axes_cm[r, c]\n",
        "        im = ax.imshow(C2, cmap='magma', origin='lower', aspect='equal')\n",
        "        ax.set_title(f'λ={lambda_list[l]*1e6:.3f} μm')\n",
        "        ax.set_xlabel('target idx')\n",
        "        ax.set_ylabel('input mode')\n",
        "\n",
        "    fig_cm.suptitle('Coupling matrices |C|^2 across wavelengths')\n",
        "    fig_cm.tight_layout()\n",
        "    fig_cm.savefig('results/coupling_matrices_6wls.png', dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    # 打印表格型结果（简洁版）\n",
        "    print('Wavelengths (μm):', [f'{wl*1e6:.3f}' for wl in lambda_list])\n",
        "    print('IL (dB):         ', [f'{v:.3f}' for v in ILs])\n",
        "    print('MDL (dB):        ', [f'{v:.3f}' for v in MDLs])\n",
        "    print('XTs_avg (dB):    ', [f'{v:.3f}' for v in XTs_avg_dB])\n",
        "    print('fidelity:        ', [f'{v:.3f}' for v in fids_l])\n",
        "    print('crosstalk:       ', [f'{v:.3f}' for v in crss_l])\n",
        "    print('efficiency:      ', [f'{v:.3f}' for v in effs_l])\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 追加可视化：λ=1.57 μm 时，10 个模式反向传播到 z=0 的强度图\n",
        "# 结果保存：results/backward_z0_modes_1p57.png\n",
        "# ==========================================\n",
        "with torch.no_grad():\n",
        "    import os\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "\n",
        "    # 选择 λ=1.57 μm 对应索引与缩放\n",
        "    l_idx = int(np.argmin(np.abs(lambda_list - lambda_c)))\n",
        "    kz_l = kz_torch_list[l_idx]\n",
        "    scale_l = lambda_c / lambda_list[l_idx]\n",
        "\n",
        "    # 从目标面出发，逐面反向传播到 z=0（逐模式并行）\n",
        "    modes_b = phi[l_idx].clone()  # (M, Ny, Nx)\n",
        "    modes_b = propagate_HK(modes_b, kz_l, -d_out)\n",
        "    modes_b = modes_b * torch.conj(torch.exp(1j * (Masks[Planes-1] * scale_l)))\n",
        "    for pl in range(Planes-2, -1, -1):\n",
        "        modes_b = propagate_HK(modes_b, kz_l, -d)\n",
        "        modes_b = modes_b * torch.conj(torch.exp(1j * (Masks[pl] * scale_l)))\n",
        "    modes_b = propagate_HK(modes_b, kz_l, -d_in)  # at z=0\n",
        "\n",
        "    # 仅取前 10 个模式（或 n_of_modes 更小者）并绘制强度\n",
        "    M = min(10, modes_b.shape[0], n_of_modes)\n",
        "    rows, cols = 2, 5\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(14, 6))\n",
        "    axes = axes.ravel()\n",
        "    for j in range(rows * cols):\n",
        "        if j < M:\n",
        "            inten = torch.abs(modes_b[j]) ** 2\n",
        "            axes[j].imshow(inten.detach().cpu().numpy(), cmap='inferno', origin='lower')\n",
        "            axes[j].set_title(f'mode {j} @ z=0')\n",
        "            axes[j].axis('off')\n",
        "        else:\n",
        "            axes[j].axis('off')\n",
        "    fig.suptitle('Backward to z=0 per-mode intensity (λ=1.57 μm)')\n",
        "    fig.tight_layout()\n",
        "    fig.savefig('results/backward_z0_modes_1p57.png', dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPqILUXObwXAeVJkmXx8z7q",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
